{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAt-K2qgcIou"
   },
   "source": [
    "# Optimization Using Gradient Descent: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYK-0rin5x7"
   },
   "source": [
    "In this assignment, you will build a simple linear regression model to predict sales based on TV marketing expenses. You will investigate three different approaches to this problem. You will use `NumPy` and `Scikit-Learn` linear regression models, as well as construct and optimize the sum of squares cost function with gradient descent from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [ 1 - Open the Dataset and State the Problem](#1)\n",
    "  - [ Exercise 1](#ex01)\n",
    "- [ 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`](#2)\n",
    "  - [ 2.1 - Linear Regression with `NumPy`](#2.1)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 2.2 - Linear Regression with `Scikit-Learn`](#2.2)\n",
    "    - [ Exercise 3](#ex03)\n",
    "    - [ Exercise 4](#ex04)\n",
    "- [ 3 - Linear Regression using Gradient Descent](#3)\n",
    "  - [ Exercise 5](#ex05)\n",
    "  - [ Exercise 6](#ex06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "Load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A library for programmatic plot generation.\n",
    "import matplotlib.pyplot as plt\n",
    "# A library for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# LinearRegression from sklearn.\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the unit tests defined for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import w2_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Open the Dataset and State the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will build a linear regression model for a simple [Kaggle dataset](https://www.kaggle.com/code/devzohaib/simple-linear-regression/notebook), saved in a file `data/tvmarketing.csv`. The dataset has only two fields: TV marketing expenses (`TV`) and sales amount (`Sales`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex01'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Use `pandas` function `pd.read_csv` to open the .csv file the from the `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "path = \"data/tvmarketing.csv\"\n",
    "\n",
    "### START CODE HERE ### (~ 1 line of code)\n",
    "adv = pd.read_csv(path)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Sales\n",
       "0  230.1   22.1\n",
       "1   44.5   10.4\n",
       "2   17.2    9.3\n",
       "3  151.5   18.5\n",
       "4  180.8   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some part of the dataset.\n",
    "adv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "\tTV\tSales\n",
    "0\t230.1\t22.1\n",
    "1\t44.5\t10.4\n",
    "2\t17.2\t9.3\n",
    "3\t151.5\t18.5\n",
    "4\t180.8\t12.9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_load_data(adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has a function to make plots from the DataFrame fields. By default, matplotlib is used at the backend. Let's use it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TV', ylabel='Sales'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv.plot(x='TV', y='Sales', kind='scatter', c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this dataset to solve a simple problem with linear regression: given a TV marketing budget, predict sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the required field of the DataFrame into variables `X` and `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "X = adv['TV']\n",
    "Y = adv['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Linear Regression with `NumPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function `np.polyfit(x, y, deg)` to fit a polynomial of degree `deg` to points $(x, y)$, minimising the sum of squared errors. You can read more in the [documentation](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html). Taking `deg = 1` you can obtain the slope `m` and the intercept `b` of the linear regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression with NumPy. Slope: 0.047536640433019736. Intercept: 7.032593549127697\n"
     ]
    }
   ],
   "source": [
    "m_numpy, b_numpy = np.polyfit(X, Y, 1)\n",
    "\n",
    "print(f\"Linear regression with NumPy. Slope: {m_numpy}. Intercept: {b_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex02'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Make predictions substituting the obtained slope and intercept coefficients into the equation $Y = mX + b$, given an array of $X$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# This is organised as a function only for grading purposes.\n",
    "def pred_numpy(m, b, X):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    Y = m*X +b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using NumPy linear regression:\n",
      "[ 9.40942557 12.7369904  20.34285287]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([50, 120, 280])\n",
    "Y_pred_numpy = pred_numpy(m_numpy, b_numpy, X_pred)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using NumPy linear regression:\\n{Y_pred_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "TV marketing expenses:\n",
    "[ 50 120 280]\n",
    "Predictions of sales using NumPy linear regression:\n",
    "[ 9.40942557 12.7369904  20.34285287]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_pred_numpy(pred_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Linear Regression with `Scikit-Learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` is an open-source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. `Scikit-learn` provides dozens of built-in machine learning algorithms and models, called **estimators**. Each estimator can be fitted to some data using its `fit` method. Full documentation can be found [here](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator object for a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "lr_sklearn = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator can learn from data calling the `fit` function. However, trying to run the following code you will get an error, as the data needs to be reshaped into 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X array: (200,)\n",
      "Shape of Y array: (200,)\n",
      "Expected 2D array, got 1D array instead:\n",
      "array=[230.1  44.5  17.2 151.5 180.8   8.7  57.5 120.2   8.6 199.8  66.1 214.7\n",
      "  23.8  97.5 204.1 195.4  67.8 281.4  69.2 147.3 218.4 237.4  13.2 228.3\n",
      "  62.3 262.9 142.9 240.1 248.8  70.6 292.9 112.9  97.2 265.6  95.7 290.7\n",
      " 266.9  74.7  43.1 228.  202.5 177.  293.6 206.9  25.1 175.1  89.7 239.9\n",
      " 227.2  66.9 199.8 100.4 216.4 182.6 262.7 198.9   7.3 136.2 210.8 210.7\n",
      "  53.5 261.3 239.3 102.7 131.1  69.   31.5 139.3 237.4 216.8 199.1 109.8\n",
      "  26.8 129.4 213.4  16.9  27.5 120.5   5.4 116.   76.4 239.8  75.3  68.4\n",
      " 213.5 193.2  76.3 110.7  88.3 109.8 134.3  28.6 217.7 250.9 107.4 163.3\n",
      " 197.6 184.9 289.7 135.2 222.4 296.4 280.2 187.9 238.2 137.9  25.   90.4\n",
      "  13.1 255.4 225.8 241.7 175.7 209.6  78.2  75.1 139.2  76.4 125.7  19.4\n",
      " 141.3  18.8 224.  123.1 229.5  87.2   7.8  80.2 220.3  59.6   0.7 265.2\n",
      "   8.4 219.8  36.9  48.3  25.6 273.7  43.  184.9  73.4 193.7 220.5 104.6\n",
      "  96.2 140.3 240.1 243.2  38.   44.7 280.7 121.  197.6 171.3 187.8   4.1\n",
      "  93.9 149.8  11.7 131.7 172.5  85.7 188.4 163.5 117.2 234.5  17.9 206.8\n",
      " 215.4 284.3  50.  164.5  19.6 168.4 222.4 276.9 248.4 170.2 276.7 165.6\n",
      " 156.6 218.5  56.2 287.6 253.8 205.  139.5 191.1 286.   18.7  39.5  75.5\n",
      "  17.2 166.8 149.7  38.2  94.2 177.  283.6 232.1].\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X array: {X.shape}\")\n",
    "print(f\"Shape of Y array: {Y.shape}\")\n",
    "\n",
    "try:\n",
    "    lr_sklearn.fit(X, Y)\n",
    "except ValueError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can increase the dimension of the array by one with `reshape` function, or there is another another way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new X array: (200, 1)\n",
      "Shape of new Y array: (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/z8_f6m_n3bqg6w1r8thbxmt80000gn/T/ipykernel_62749/3728240640.py:1: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_sklearn = X[:, np.newaxis]\n",
      "/var/folders/w2/z8_f6m_n3bqg6w1r8thbxmt80000gn/T/ipykernel_62749/3728240640.py:2: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  Y_sklearn = Y[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "X_sklearn = X[:, np.newaxis]\n",
    "Y_sklearn = Y[:, np.newaxis]\n",
    "\n",
    "print(f\"Shape of new X array: {X_sklearn.shape}\")\n",
    "print(f\"Shape of new Y array: {Y_sklearn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex03'></a>\n",
    "### Exercise \n",
    "\n",
    "Fit the linear regression model passing `X_sklearn` and `Y_sklearn` arrays into the function `lr_sklearn.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ### (~ 1 line of code)\n",
    "lr_sklearn.fit(X_sklearn, Y_sklearn)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression using Scikit-Learn. Slope: [[0.04753664]]. Intercept: [7.03259355]\n"
     ]
    }
   ],
   "source": [
    "m_sklearn = lr_sklearn.coef_\n",
    "b_sklearn = lr_sklearn.intercept_\n",
    "\n",
    "print(f\"Linear regression using Scikit-Learn. Slope: {m_sklearn}. Intercept: {b_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "Linear regression using Scikit-Learn. Slope: [[0.04753664]]. Intercept: [7.03259355]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_sklearn_fit(lr_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you have got the same result as with the `NumPy` function `polyfit`. Now, to make predictions it is convenient to use `Scikit-Learn` function `predict`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex04'></a>\n",
    "### Exercise 4\n",
    "\n",
    "\n",
    "Increase the dimension of the $X$ array using the function `np.newaxis` (see an example above) and pass the result to the `lr_sklearn.predict` function to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# This is organised as a function only for grading purposes.\n",
    "def pred_sklearn(X, lr_sklearn):\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    X_2D = X[:, np.newaxis]\n",
    "    Y = lr_sklearn.predict(X_2D)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using Scikit_Learn linear regression:\n",
      "[[ 9.40942557 12.7369904  20.34285287]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_sklearn = pred_sklearn(X_pred, lr_sklearn)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "TV marketing expenses:\n",
    "[ 50 120 280]\n",
    "Predictions of sales using Scikit_Learn linear regression:\n",
    "[[ 9.40942557 12.7369904  20.34285287]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_sklearn_predict(pred_sklearn, lr_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the linear regression line and the predictions by running the following code. The regression line is red and the predicted points are blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1786ea790>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
    "ax.plot(X, Y, 'o', color='black')\n",
    "ax.set_xlabel('TV')\n",
    "ax.set_ylabel('Sales')\n",
    "\n",
    "ax.plot(X, m_sklearn[0][0]*X+b_sklearn[0], color='red')\n",
    "ax.plot(X_pred, Y_pred_sklearn, 'o', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Linear Regression using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fit the models automatically are convenient to use, but for an in-depth understanding of the model and the maths behind it is good to implement an algorithm by yourself. Let's try to find linear regression coefficients $m$ and $b$, by minimising the difference between original values $y^{(i)}$ and predicted values $\\hat{y}^{(i)}$ with the **loss function** $L\\left(w, b\\right)  = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2$ for each of the training examples. Division by $2$ is taken just for scaling purposes, you will see the reason below, calculating partial derivatives.\n",
    "\n",
    "To compare the resulting vector of the predictions $\\hat{Y}$ with the vector $Y$ of original values $y^{(i)}$, you can take an average of the loss function values for each of the training examples:\n",
    "\n",
    "$$E\\left(m, b\\right) = \\frac{1}{2n}\\sum_{i=1}^{n} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2 = \n",
    "\\frac{1}{2n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)^2,\\tag{1}$$\n",
    "\n",
    "where $n$ is a number of data points. This function is called the sum of squares **cost function**. To use gradient descent algorithm, calculate partial derivatives as:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E }{ \\partial m } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)x^{(i)},\\\\\n",
    "\\frac{\\partial E }{ \\partial b } &= \n",
    "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right),\n",
    "\\tag{2}\\end{align}\n",
    "\n",
    "and update the parameters iteratively using the expressions\n",
    "\n",
    "\\begin{align}\n",
    "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
    "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
    "\\tag{3}\\end{align}\n",
    "\n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original arrays `X` and `Y` have different units. To make gradient descent algorithm efficient, you need to bring them to the same units. A common approach to it is called **normalization**: substract the mean value of the array from each of the elements in the array and divide them by standard deviation (a statistical measure of the amount of dispersion of a set of values). If you are not familiar with mean and standard deviation, do not worry about this for now - this is covered in the next Course of Specialization.\n",
    "\n",
    "Normalization is not compulsory - gradient descent would work without it. But due to different units of `X` and `Y`, the cost function will be much steeper. Then you would need to take a significantly smaller learning rate $\\alpha$, and the algorithm will require thousands of iterations to converge instead of a few dozens. Normalization helps to increase the efficiency of the gradient descent algorithm.\n",
    "\n",
    "Normalization is implemented in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "X_norm = (X - np.mean(X))/np.std(X)\n",
    "Y_norm = (Y - np.mean(Y))/np.std(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cost function according to the equation $(1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def E(m, b, X, Y):\n",
    "    return 1/(2*len(Y))*np.sum((m*X + b - Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex05'></a>\n",
    "### Exercise 5\n",
    "\n",
    "\n",
    "Define functions `dEdm` and `dEdb` to calculate partial derivatives according to the equations $(2)$. This can be done using vector form of the input data `X` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def dEdm(m, b, X, Y):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    # Use the following line as a hint, replacing all None.\n",
    "    res = 1/len(X)*np.dot(m*X + b - Y, X)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return res\n",
    "    \n",
    "\n",
    "def dEdb(m, b, X, Y):\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    # Replace None writing the required expression fully.\n",
    "    res = 1/len(X)*np.dot(m*X + b - Y,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7822244248616064\n",
      "-1.0\n",
      "0.21777557513839416\n",
      "-0.2177755751383945\n"
     ]
    }
   ],
   "source": [
    "print(dEdm(0, 0, X_norm, Y_norm))\n",
    "print(dEdb(0, 0, X_norm, Y_norm))\n",
    "print(dEdm(1, 5, X_norm, Y_norm))\n",
    "print(dEdb(1, 5, X_norm, Y_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "-0.7822244248616067\n",
    "5.098005351200641e-16\n",
    "0.21777557513839355\n",
    "5.000000000000002\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case \"default_check\". Wrong output of dEdb for m = 0, b = 0. \n",
      "\tExpected: \n",
      "1.687538997430238e-16\n",
      "\tGot: \n",
      "-1.0\n",
      "Test case \"extra_check\". Wrong output of dEdb for m = 1, b = 5. \n",
      "\tExpected: \n",
      "5.000000000000001\n",
      "\tGot: \n",
      "-0.2177755751383945\n",
      "\u001b[92m 2  Tests passed\n",
      "\u001b[91m 2  Tests failed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_partial_derivatives(dEdm, dEdb, X_norm, Y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex06'></a>\n",
    "### Exercise 6\n",
    "\n",
    "\n",
    "Implement gradient descent using expressions $(3)$:\n",
    "\\begin{align}\n",
    "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
    "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
    "\\end{align}\n",
    "\n",
    "where $\\alpha$ is the `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def gradient_descent(dEdm, dEdb, m, b, X, Y, learning_rate = 0.001, num_iterations = 1000, print_cost=False):\n",
    "    for iteration in range(num_iterations):\n",
    "        ### START CODE HERE ### (~ 2 lines of code)\n",
    "        m_new = m - learning_rate*dEdm(m, b, X, Y)\n",
    "        b_new = b - learning_rate*dEdb(m, b, X, Y)\n",
    "        ### END CODE HERE ###\n",
    "        m = m_new\n",
    "        b = b_new\n",
    "        if print_cost:\n",
    "            print (f\"Cost after iteration {iteration}: {E(m, b, X, Y)}\")\n",
    "        \n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4946040826958948, 0.7750163432709269)\n",
      "(0.9791767513915026, 5.022524041248461)\n"
     ]
    }
   ],
   "source": [
    "print(gradient_descent(dEdm, dEdb, 0, 0, X_norm, Y_norm))\n",
    "print(gradient_descent(dEdm, dEdb, 1, 5, X_norm, Y_norm, learning_rate = 0.01, num_iterations = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __Expected Output__ \n",
    "\n",
    "```Python\n",
    "(0.49460408269589495, -3.489285249624889e-16)\n",
    "(0.9791767513915026, 4.521910375044022)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case \"default_check\". Wrong output value b of the function gradient_descent.\n",
      "m = 0, b = 0, learning_rate = 0.001, num_iterations = 1000. \n",
      "\tExpected: \n",
      "-1.367306268207353e-16\n",
      "\tGot: \n",
      "0.7750163432709269\n",
      "Test case \"extra_check\". Wrong output value b of the function gradient_descent.\n",
      "m = 1, b = 5, learning_rate = 0.01, num_iterations = 10. \n",
      "\tExpected: \n",
      "4.521910375044022\n",
      "\tGot: \n",
      "5.022524041248461\n",
      "\u001b[92m 2  Tests passed\n",
      "\u001b[91m 2  Tests failed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_gradient_descent(gradient_descent, dEdm, dEdb, X_norm, Y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the gradient descent method starting from the initial point $\\left(m_0, b_0\\right)=\\left(0, 0\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.9262999755919663\n",
      "Cost after iteration 1: 1.3480804683955592\n",
      "Cost after iteration 2: 2.222220069321951\n",
      "Cost after iteration 3: 3.2541434889501843\n",
      "Cost after iteration 4: 4.518275247102447\n",
      "Cost after iteration 5: 5.995623329334312\n",
      "Cost after iteration 6: 7.690767351906969\n",
      "Cost after iteration 7: 9.60263354054477\n",
      "Cost after iteration 8: 11.731468155973571\n",
      "Cost after iteration 9: 14.077215642300693\n",
      "Cost after iteration 10: 16.639888371351244\n",
      "Cost after iteration 11: 19.419483616626767\n",
      "Cost after iteration 12: 22.416001973853483\n",
      "Cost after iteration 13: 25.62944331380083\n",
      "Cost after iteration 14: 29.059807664331995\n",
      "Cost after iteration 15: 32.7070950194709\n",
      "Cost after iteration 16: 36.57130538049346\n",
      "Cost after iteration 17: 40.65243874712838\n",
      "Cost after iteration 18: 44.95049511943311\n",
      "Cost after iteration 19: 49.46547449739553\n",
      "Cost after iteration 20: 54.197376881018194\n",
      "Cost after iteration 21: 59.14620227030056\n",
      "Cost after iteration 22: 64.31195066524275\n",
      "Cost after iteration 23: 69.69462206584473\n",
      "Cost after iteration 24: 75.2942164721065\n",
      "Cost after iteration 25: 81.1107338840281\n",
      "Cost after iteration 26: 87.14417430160945\n",
      "Cost after iteration 27: 93.39453772485062\n",
      "Cost after iteration 28: 99.86182415375161\n",
      "Cost after iteration 29: 106.54603358831237\n",
      "Gradient descent result: m_min, b_min = 0.7822244248616045, 14.584373220247581\n"
     ]
    }
   ],
   "source": [
    "m_initial = 0; b_initial = 0; num_iterations = 30; learning_rate = 1.2\n",
    "m_gd, b_gd = gradient_descent(dEdm, dEdb, m_initial, b_initial, \n",
    "                              X_norm, Y_norm, learning_rate, num_iterations, print_cost=True)\n",
    "\n",
    "print(f\"Gradient descent result: m_min, b_min = {m_gd}, {b_gd}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that the initial datasets were normalized. To make the predictions, you need to normalize `X_pred` array, calculate `Y_pred` with the linear regression coefficients `m_gd`, `b_gd` and then **denormalize** the result (perform the reverse process of normalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV marketing expenses:\n",
      "[ 50 120 280]\n",
      "Predictions of sales using Scikit_Learn linear regression:\n",
      "[[ 9.40942557 12.7369904  20.34285287]]\n",
      "Predictions of sales using Gradient Descent:\n",
      "[85.31228766 88.63985249 96.24571496]\n"
     ]
    }
   ],
   "source": [
    "X_pred = np.array([50, 120, 280])\n",
    "# Use the same mean and standard deviation of the original training array X\n",
    "X_pred_norm = (X_pred - np.mean(X))/np.std(X)\n",
    "Y_pred_gd_norm = m_gd*X_pred_norm + b_gd\n",
    "# Use the same mean and standard deviation of the original training array Y\n",
    "Y_pred_gd = Y_pred_gd_norm * np.std(Y) + np.mean(Y)\n",
    "\n",
    "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
    "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")\n",
    "print(f\"Predictions of sales using Gradient Descent:\\n{Y_pred_gd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have gotten similar results as in the previous sections. \n",
    "\n",
    "Well done! Now you know how gradient descent algorithm can be applied to train a real model. Re-producing results manually for a simple case should give you extra confidence that you understand what happends under the hood of commonly used functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "478841ab876a4250505273c8a697bbc1b6b194054b009c227dc606f17fb56272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
